{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XKZwaOnWAJo"
      },
      "source": [
        "# **1. Introduction**\n",
        "\n",
        "**Goals**:\n",
        "\n",
        "\n",
        "*  Learn the usage of textual data\n",
        "*  Get to know popular NLP-frameworks (NLTK, Spacy, Gensim)\n",
        "*  Learn how to preprocess textual data for further analysis (tokenization, stemming/lemmatization, stopword removal, vectorization, similarity computation)\n",
        "* Get to know popular ML framework Scikit-learn\n",
        "* Build model and evaluate it on test set\n",
        "---\n",
        "\n",
        "**Credit**: This tutorial is partly based on [blog post 1](https://curiousily.com/posts/create-dataset-for-sentiment-analysis-by-scraping-google-play-app-reviews-using-python/), [blog post 2](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/) and the series \"Fundamentals of NLP\" by  Elvis Saravia ( [Twitter](https://twitter.com/omarsar0) | [LinkedIn](https://www.linkedin.com/in/omarsar/)), where the full project is maintained [here](https://github.com/dair-ai/nlp_fundamentals).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSCFR2xLvrBo"
      },
      "source": [
        "Before we start, we can first check the installed library  by following command line:\n",
        "\n",
        "* ``pip freeze``: list all the python libaries & versions\n",
        "* ``pip show <package_name>``: list the selected package_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W9223RYwTgQ",
        "outputId": "60110cbf-34b6-4695-9495-7fb9b12509dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "alabaster==0.7.13\n",
            "albumentations==1.2.1\n",
            "altair==4.2.2\n",
            "anyio==3.6.2\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.2.0\n",
            "arviz==0.15.1\n",
            "astropy==5.2.2\n",
            "astunparse==1.6.3\n",
            "attrs==23.1.0\n",
            "audioread==3.0.0\n",
            "autograd==1.5\n",
            "Babel==2.12.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bleach==6.0.0\n",
            "blis==0.7.9\n",
            "blosc2==2.0.0\n",
            "bokeh==2.4.3\n",
            "branca==0.6.0\n",
            "build==0.10.0\n",
            "CacheControl==0.12.11\n",
            "cached-property==1.5.2\n",
            "cachetools==5.3.0\n",
            "catalogue==2.0.8\n",
            "certifi==2022.12.7\n",
            "cffi==1.15.1\n",
            "chardet==4.0.0\n",
            "charset-normalizer==2.0.12\n",
            "chex==0.1.7\n",
            "click==8.1.3\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.25.2\n",
            "cmdstanpy==1.1.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "confection==0.0.4\n",
            "cons==0.4.5\n",
            "contextlib2==0.6.0.post1\n",
            "contourpy==1.0.7\n",
            "convertdate==2.4.0\n",
            "cryptography==40.0.2\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.3.0\n",
            "cvxpy==1.3.1\n",
            "cycler==0.11.0\n",
            "cymem==2.0.7\n",
            "Cython==0.29.34\n",
            "dask==2022.12.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.16\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2022.12.1\n",
            "dlib==19.24.1\n",
            "dm-tree==0.1.8\n",
            "docutils==0.16\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.7.1\n",
            "earthengine-api==0.1.350\n",
            "easydict==1.10\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n",
            "entrypoints==0.4\n",
            "ephem==4.1.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.2.0\n",
            "etuples==0.3.8\n",
            "exceptiongroup==1.1.1\n",
            "fastai==2.7.12\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.16.3\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.1\n",
            "filelock==3.12.0\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.4\n",
            "flatbuffers==23.3.3\n",
            "flax==0.6.9\n",
            "folium==0.14.0\n",
            "fonttools==4.39.3\n",
            "frozendict==2.3.7\n",
            "fsspec==2023.4.0\n",
            "future==0.18.3\n",
            "gast==0.4.0\n",
            "GDAL==3.3.2\n",
            "gdown==4.6.6\n",
            "gensim==4.3.1\n",
            "geographiclib==2.0\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.11.0\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.0\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-bigquery==3.9.0\n",
            "google-cloud-bigquery-storage==2.19.1\n",
            "google-cloud-core==2.3.2\n",
            "google-cloud-datastore==2.15.1\n",
            "google-cloud-firestore==2.11.0\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.1\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=8039831a3aae11b986530adfdf4850a5ef193d8000f4d70d5cf75071362e09e4\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.5.0\n",
            "googleapis-common-protos==1.59.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==2.0.2\n",
            "grpcio==1.54.0\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.1.0\n",
            "h5py==3.8.0\n",
            "holidays==0.25\n",
            "holoviews==1.15.4\n",
            "html5lib==1.1\n",
            "httpimport==1.3.0\n",
            "httplib2==0.21.0\n",
            "humanize==4.6.0\n",
            "hyperopt==0.2.7\n",
            "idna==3.4\n",
            "imageio==2.25.1\n",
            "imageio-ffmpeg==0.4.8\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-resources==5.12.0\n",
            "imutils==0.5.4\n",
            "inflect==6.0.4\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.1.0\n",
            "ipykernel==5.5.6\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.4.1\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.10\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.10+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=fe53205ef12727c80ed5ac2d4506d6732c0c3db69ede4565a7d4df98e609af84\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.2.0\n",
            "jsonpickle==3.0.1\n",
            "jsonschema==4.3.3\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.3.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==3.0.7\n",
            "kaggle==1.5.13\n",
            "keras==2.12.0\n",
            "kiwisolver==1.4.4\n",
            "korean-lunar-calendar==0.3.1\n",
            "langcodes==3.3.0\n",
            "lazy_loader==0.2\n",
            "libclang==16.0.0\n",
            "librosa==0.10.0.post2\n",
            "lightgbm==3.3.5\n",
            "lit==16.0.5\n",
            "llvmlite==0.39.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.5\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.9.2\n",
            "Markdown==3.4.3\n",
            "markdown-it-py==2.2.0\n",
            "MarkupSafe==2.1.2\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.8.1\n",
            "mkl==2019.0\n",
            "ml-dtypes==0.1.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==9.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.5\n",
            "multipledispatch==0.6.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.9\n",
            "music21==8.1.0\n",
            "natsort==8.3.1\n",
            "nbclient==0.7.4\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.8.0\n",
            "nest-asyncio==1.5.6\n",
            "networkx==3.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.4.8\n",
            "numba==0.56.4\n",
            "numexpr==2.8.4\n",
            "numpy==1.22.4\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.7.0.72\n",
            "opencv-python==4.7.0.72\n",
            "opencv-python-headless==4.7.0.72\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.5\n",
            "orbax-checkpoint==0.2.1\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.1\n",
            "palettable==3.3.3\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.17.9\n",
            "pandocfilters==1.5.0\n",
            "panel==0.14.4\n",
            "param==1.13.0\n",
            "parso==0.8.3\n",
            "partd==1.4.0\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.1\n",
            "patsy==0.5.3\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==8.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==3.3.0\n",
            "plotly==5.13.1\n",
            "plotnine==0.10.1\n",
            "pluggy==1.0.0\n",
            "polars==0.17.3\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.8\n",
            "prettytable==0.7.2\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.16.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.38\n",
            "prophet==1.1.3\n",
            "proto-plus==1.22.2\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.6\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.5.0\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.6\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.7\n",
            "pydata-google-auth==1.7.0\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyerfa==2.0.0.3\n",
            "pygame==2.3.0\n",
            "Pygments==2.14.0\n",
            "PyGObject==3.36.0\n",
            "pymc==5.1.2\n",
            "PyMeeus==0.5.12\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.9\n",
            "pyproject_hooks==1.0.0\n",
            "pyrsistent==0.19.3\n",
            "PySocks==1.7.1\n",
            "pytensor==2.10.1\n",
            "pytest==7.2.2\n",
            "python-apt==0.0.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.5.2\n",
            "pytz==2022.7.1\n",
            "pytz-deprecation-shim==0.1.0.post0\n",
            "pyviz-comms==2.2.1\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7\n",
            "qudida==0.0.4\n",
            "regex==2022.10.31\n",
            "requests==2.27.1\n",
            "requests-oauthlib==1.3.1\n",
            "requests-unixsocket==0.2.0\n",
            "requirements-parser==0.5.0\n",
            "rich==13.3.4\n",
            "rpy2==3.5.5\n",
            "rsa==4.9\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.10.1\n",
            "scs==3.2.3\n",
            "seaborn==0.12.2\n",
            "Send2Trash==1.8.0\n",
            "shapely==2.0.1\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.3.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.4.1\n",
            "soxr==0.3.5\n",
            "spacy==3.5.2\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.4\n",
            "Sphinx==3.5.4\n",
            "sphinxcontrib-applehelp==1.0.4\n",
            "sphinxcontrib-devhelp==1.0.2\n",
            "sphinxcontrib-htmlhelp==2.0.1\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.3\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "SQLAlchemy==2.0.10\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.6\n",
            "statsmodels==0.13.5\n",
            "sympy==1.11.1\n",
            "tables==3.8.0\n",
            "tabulate==0.8.10\n",
            "tblib==1.7.0\n",
            "tenacity==8.2.2\n",
            "tensorboard==2.12.2\n",
            "tensorboard-data-server==0.7.0\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow==2.12.0\n",
            "tensorflow-datasets==4.9.2\n",
            "tensorflow-estimator==2.12.0\n",
            "tensorflow-gcs-config==2.12.0\n",
            "tensorflow-hub==0.13.0\n",
            "tensorflow-io-gcs-filesystem==0.32.0\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.20.1\n",
            "tensorstore==0.1.36\n",
            "termcolor==2.3.0\n",
            "terminado==0.17.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.9\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2023.4.12\n",
            "tinycss2==1.2.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a7a49d459bf4862f64f7bc1a68beccf8881c2fa9f3e0569608e16ba6f85ebf7b\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=26692645ea061a005c57ec581a2d0425210ac6ba9f923edf11cc9b0ef3a111e9\n",
            "torchdata==0.6.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.15.2\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=19ca4ab5d6179bbe53cff79df1a855ee6533c2861ddc7389f68349d8b9f8302a\n",
            "tornado==6.3.1\n",
            "tqdm==4.65.0\n",
            "traitlets==5.7.1\n",
            "triton==2.0.0\n",
            "tweepy==4.13.0\n",
            "typer==0.7.0\n",
            "types-setuptools==67.8.0.0\n",
            "typing_extensions==4.5.0\n",
            "tzdata==2023.3\n",
            "tzlocal==4.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==1.26.15\n",
            "vega-datasets==0.9.0\n",
            "wasabi==1.1.1\n",
            "wcwidth==0.2.6\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.5.1\n",
            "Werkzeug==2.3.0\n",
            "widgetsnbextension==3.6.4\n",
            "wordcloud==1.8.2.2\n",
            "wrapt==1.14.1\n",
            "xarray==2022.12.0\n",
            "xarray-einstats==0.5.1\n",
            "xgboost==1.7.5\n",
            "xlrd==2.0.1\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.18\n",
            "zict==3.0.0\n",
            "zipp==3.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm6Q8gG8xSFH",
        "outputId": "b69db769-9715-4d48-8f00-442983249cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: nltk\n",
            "Version: 3.8.1\n",
            "Summary: Natural Language Toolkit\n",
            "Home-page: https://www.nltk.org/\n",
            "Author: NLTK Team\n",
            "Author-email: nltk.team@gmail.com\n",
            "License: Apache License, Version 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: click, joblib, regex, tqdm\n",
            "Required-by: textblob\n"
          ]
        }
      ],
      "source": [
        "!pip show nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jrMMQpfjMFfq"
      },
      "outputs": [],
      "source": [
        "# Initialize random seed to get consistent result\n",
        "import numpy as np\n",
        "import random\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIFRexvWVwAH"
      },
      "source": [
        "# **2. Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1Mk2vuwFFT"
      },
      "source": [
        "<!-- We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the [General Language Understanding Evaluation (GLUE) Benchmark](https://gluebenchmark.com/). -->\n",
        "We'll use [The Google Play reviews Dataset](https://curiousily.com/posts/create-dataset-for-sentiment-analysis-by-scraping-google-play-app-reviews-using-python/) provided by Venelin Valkov. The dataset can then be used for sentiment analysis classification.\n",
        "\n",
        "You can either download it locally and reupload it in specific folder in your Google Drive, or you can simply run the following code to download it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "h4O91aJ6Sj7R",
        "outputId": "28947fba-56df-40f4-eafd-ed546c887f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15746, 11)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           userName                                          userImage  \\\n",
              "0     Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n",
              "1      Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n",
              "2     steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n",
              "3  Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n",
              "4     Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0  Update: After getting a response from the deve...      1             21   \n",
              "1  Used it for a fair amount of time without any ...      1             11   \n",
              "2  Your app sucks now!!!!! Used to be good but no...      1             17   \n",
              "3  It seems OK, but very basic. Recurring tasks n...      1            192   \n",
              "4  Absolutely worthless. This app runs a prohibit...      1             42   \n",
              "\n",
              "  reviewCreatedVersion                   at  \\\n",
              "0             4.17.0.3  2020-04-05 22:25:57   \n",
              "1             4.17.0.3  2020-04-04 13:40:01   \n",
              "2             4.17.0.3  2020-04-01 16:18:13   \n",
              "3             4.17.0.2  2020-03-12 08:17:34   \n",
              "4             4.17.0.2  2020-03-14 17:41:01   \n",
              "\n",
              "                                        replyContent            repliedAt  \\\n",
              "0  According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n",
              "1  It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n",
              "2  This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n",
              "3  We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n",
              "4  We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n",
              "\n",
              "       sortOrder      appId  \n",
              "0  most_relevant  com.anydo  \n",
              "1  most_relevant  com.anydo  \n",
              "2  most_relevant  com.anydo  \n",
              "3  most_relevant  com.anydo  \n",
              "4  most_relevant  com.anydo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-173b86de-c624-4a28-a88c-a727ccd15b47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173b86de-c624-4a28-a88c-a727ccd15b47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-173b86de-c624-4a28-a88c-a727ccd15b47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-173b86de-c624-4a28-a88c-a727ccd15b47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Load the data via pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/reviews.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8wnXWebjTecS",
        "outputId": "7ee01223-267f-4f90-bf83-9b08e18f1bc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              score  thumbsUpCount\n",
              "count  15746.000000   15746.000000\n",
              "mean       3.062365       3.992570\n",
              "std        1.310503      17.058478\n",
              "min        1.000000       0.000000\n",
              "25%        2.000000       0.000000\n",
              "50%        3.000000       0.000000\n",
              "75%        4.000000       1.000000\n",
              "max        5.000000     448.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6ae4c2b-8a3d-422d-be73-819475aafb81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15746.000000</td>\n",
              "      <td>15746.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.062365</td>\n",
              "      <td>3.992570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.310503</td>\n",
              "      <td>17.058478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>448.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6ae4c2b-8a3d-422d-be73-819475aafb81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6ae4c2b-8a3d-422d-be73-819475aafb81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6ae4c2b-8a3d-422d-be73-819475aafb81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Print the data infos & check for missing values\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nbVu7OicV2bB",
        "outputId": "c830837d-66d1-46cc-8897-29035597d47a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  score\n",
              "0  Update: After getting a response from the deve...      1\n",
              "1  Used it for a fair amount of time without any ...      1\n",
              "2  Your app sucks now!!!!! Used to be good but no...      1\n",
              "3  It seems OK, but very basic. Recurring tasks n...      1\n",
              "4  Absolutely worthless. This app runs a prohibit...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-621ee7bf-10f9-4c2a-9217-c58f5846cdef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621ee7bf-10f9-4c2a-9217-c58f5846cdef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-621ee7bf-10f9-4c2a-9217-c58f5846cdef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-621ee7bf-10f9-4c2a-9217-c58f5846cdef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Actually we only need the content(i.e. review) & the sentiment score for classification\n",
        "df = df[['content', 'score']]\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "1aRee_tWWhGq",
        "outputId": "f8199865-7c8f-4778-e7df-2b14ca0d0819"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We can plot the score & check for the distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(x=df.score)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "w8QhZTegZR-l",
        "outputId": "d28168dd-2c5d-4963-ce85-f089d081769b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'negative'), Text(1, 0, 'neutral'), Text(2, 0, 'positive')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Since it's highly imbalanced, we can convert the score into 3 categories: negative(<3), neutral(=3), positive(>3)\n",
        "# And replot it\n",
        "def to_sentiment(score):\n",
        "    score = int(score)\n",
        "    if score <= 2:\n",
        "        return 0\n",
        "    elif score == 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "df['sentiment'] = df.score.apply(to_sentiment)\n",
        "\n",
        "# Plot the score distribution after conversion\n",
        "ax = sns.countplot(x=df.sentiment)\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCgy1XjEcEQT"
      },
      "source": [
        "# **3. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "19FMY8c7b_1C",
        "outputId": "4998aff0-4c8c-4a7e-84a2-f1b85a905e49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Update: After getting a response from the developer I would change my rating to 0 stars if possible. These guys hide behind confusing and opaque terms and refuse to budge at all. I'm so annoyed that my money has been lost to them! Really terrible customer experience. Original: Be very careful when signing up for a free trial of this app. If you happen to go over they automatically charge you for a full years subscription and refuse to refund. Terrible customer experience and the app is just OK.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Before preprocessing, we can first check the review content\n",
        "df.content[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "vgEB9R0hdi_f",
        "outputId": "4ca06548-6b4d-4682-efca-52f7b2cd3fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It seems OK, but very basic. Recurring tasks need some work to be actually useful. For example, it would be nice to be able to set a task to be recurring on the first of every month, without only being able to set that up on the first of the month. Edit; I also just noticed that there is no dark theme. Both may be available as paid for options, but I'll never know, since they are basic options and without them, I have no reason to try this app, and thus will never pay for actual premium options.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.content[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BPXrTKHe086"
      },
      "source": [
        "## **3.1 Tokenization**\n",
        "<div>\n",
        "<img src=https://drive.google.com/uc?export=view&id=1h0ZNzohff1nUWMerrW50eDxY99ArRJTK width=\"800\">\n",
        "</div>\n",
        "\n",
        "With any typical NLP task, one of the first steps is to tokenize your pieces of text into its individual words/tokens (process demonstrated in the figure above), the result of which is used to create so-called vocabularies that will be used in the langauge model you plan to build. This is actually one of the techniques that we will use the most throughout this series but here we stick to the basics.\n",
        "\n",
        "Below I am showing you an example of a simple tokenizer without following any standards. All it does is extract tokens based on a white space seperator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YB4Yd-9erXB",
        "outputId": "8e873f40-9b94-4b65-d6ff-adc8b6719d94",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 0: Update:\n",
            "Token 1: After\n",
            "Token 2: getting\n",
            "Token 3: a\n",
            "Token 4: response\n",
            "Token 5: from\n",
            "Token 6: the\n",
            "Token 7: developer\n",
            "Token 8: I\n",
            "Token 9: would\n",
            "Token 10: change\n",
            "Token 11: my\n",
            "Token 12: rating\n",
            "Token 13: to\n",
            "Token 14: 0\n",
            "Token 15: stars\n",
            "Token 16: if\n",
            "Token 17: possible.\n",
            "Token 18: These\n",
            "Token 19: guys\n",
            "Token 20: hide\n",
            "Token 21: behind\n",
            "Token 22: confusing\n",
            "Token 23: and\n",
            "Token 24: opaque\n",
            "Token 25: terms\n",
            "Token 26: and\n",
            "Token 27: refuse\n",
            "Token 28: to\n",
            "Token 29: budge\n",
            "Token 30: at\n",
            "Token 31: all.\n",
            "Token 32: I'm\n",
            "Token 33: so\n",
            "Token 34: annoyed\n",
            "Token 35: that\n",
            "Token 36: my\n",
            "Token 37: money\n",
            "Token 38: has\n",
            "Token 39: been\n",
            "Token 40: lost\n",
            "Token 41: to\n",
            "Token 42: them!\n",
            "Token 43: Really\n",
            "Token 44: terrible\n",
            "Token 45: customer\n",
            "Token 46: experience.\n",
            "Token 47: Original:\n",
            "Token 48: Be\n",
            "Token 49: very\n",
            "Token 50: careful\n",
            "Token 51: when\n",
            "Token 52: signing\n",
            "Token 53: up\n",
            "Token 54: for\n",
            "Token 55: a\n",
            "Token 56: free\n",
            "Token 57: trial\n",
            "Token 58: of\n",
            "Token 59: this\n",
            "Token 60: app.\n",
            "Token 61: If\n",
            "Token 62: you\n",
            "Token 63: happen\n",
            "Token 64: to\n",
            "Token 65: go\n",
            "Token 66: over\n",
            "Token 67: they\n",
            "Token 68: automatically\n",
            "Token 69: charge\n",
            "Token 70: you\n",
            "Token 71: for\n",
            "Token 72: a\n",
            "Token 73: full\n",
            "Token 74: years\n",
            "Token 75: subscription\n",
            "Token 76: and\n",
            "Token 77: refuse\n",
            "Token 78: to\n",
            "Token 79: refund.\n",
            "Token 80: Terrible\n",
            "Token 81: customer\n",
            "Token 82: experience\n",
            "Token 83: and\n",
            "Token 84: the\n",
            "Token 85: app\n",
            "Token 86: is\n",
            "Token 87: just\n",
            "Token 88: OK.\n"
          ]
        }
      ],
      "source": [
        "# You can simply use split to tokenize the text by whitespace\n",
        "doc = df.content[0]\n",
        "for i, w in enumerate(doc.split(\" \")):\n",
        "    print(\"Token \" + str(i) + \": \" + w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfwo0Oyc8Elz"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "**(a) What are the problems here with only the split function for tokenization?**\n",
        "\n",
        "White space tokenization, where words are simply split by spaces, is a common technique for natural language processing (NLP). However, it can lead to several problems:\n",
        "\n",
        "* **Punctuation**: White space tokenization does not take into account punctuation marks, which can change the meaning of a sentence. For example, \"Let's eat, grandma!\" and \"Let's eat grandma!\" have completely different meanings.\n",
        "\n",
        "* **Contractions**: White space tokenization can also create problems with contractions, such as \"can't\" and \"won't\". These are typically treated as a single word, but can also be split into two words (\"can\" and \"not\").\n",
        "\n",
        "* **Hyphenated words**: White space tokenization can also have difficulty with hyphenated words, which can be treated as separate words or as a single unit depending on the context.\n",
        "\n",
        "* **Multi-word expressions**: White space tokenization also struggles with multi-word expressions, such as \"New York\" or \"United States\". These can be split into separate words or treated as a single unit depending on the context.\n",
        "\n",
        "* **Ambiguity**: White space tokenization can be ambiguous, especially when dealing with languages that do not use spaces to separate words, such as Chinese and Japanese. In these cases, the meaning of the text can change depending on how it is segmented.\n",
        "\n",
        "**(b) How can we improve the tokenization?**\n",
        "\n",
        "Tokenization can come in different forms. For instance, more recently a lot of state-of-the-art NLP models such as [BERT](https://arxiv.org/pdf/1810.04805.pdf) make use of `subword` tokens in which frequent combinations of characters also form part of the vocabulary. This helps to deal with the so-called out of vocabulary (OOV) problem. We will discuss this in upcoming chapters, but if you are interested in reading more about this now, check this [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOUlECPwYYj2"
      },
      "source": [
        "### **3.1.1 spaCy**\n",
        "\n",
        "To demonstrate how you can achieve more reliable tokenization, we are going to use [spaCy](https://spacy.io/), which is an impressive and robust Python library for natural language processing. It comes with pretrained pipelines and currently supports tokenization and training for 60+ languages. It features state-of-the-art speed and neural network models for tagging, parsing, named entity recognition, text classification and more.\n",
        "\n",
        "In particular, we are going to use the built-in tokenizer found [here](https://spacy.io/usage/linguistic-features#tokenization). You can also find the useful models for different languages [here](https://spacy.io/usage/models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjh2Wmjf8YMh",
        "outputId": "f7b2b4ca-405c-4509-aadd-9b23c6fe1969",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: spacy\n",
            "Version: 3.5.2\n",
            "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
            "Home-page: https://spacy.io\n",
            "Author: Explosion\n",
            "Author-email: contact@explosion.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: catalogue, cymem, jinja2, langcodes, murmurhash, numpy, packaging, pathy, preshed, pydantic, requests, setuptools, smart-open, spacy-legacy, spacy-loggers, srsly, thinc, tqdm, typer, wasabi\n",
            "Required-by: en-core-web-sm, fastai\n"
          ]
        }
      ],
      "source": [
        "# Colab has already spacy library installed\n",
        "!pip show spacy\n",
        "# If you don't have it in your local machine, you can simply download the libraries\n",
        "#!pip install -U spacy\n",
        "#!pip install -U spacy-lookups-data\n",
        "#!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpfzJRYL8dVB",
        "outputId": "7ced149c-07fb-49ad-e5dd-910568e0a96e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 0: Used (VERB)\n",
            "Token 1: it (PRON)\n",
            "Token 2: for (ADP)\n",
            "Token 3: a (DET)\n",
            "Token 4: fair (ADJ)\n",
            "Token 5: amount (NOUN)\n",
            "Token 6: of (ADP)\n",
            "Token 7: time (NOUN)\n",
            "Token 8: without (ADP)\n",
            "Token 9: any (DET)\n",
            "Token 10: problems (NOUN)\n",
            "Token 11: . (PUNCT)\n",
            "Token 12: Suddenly (ADV)\n",
            "Token 13: then (ADV)\n",
            "Token 14: asked (VERB)\n",
            "Token 15: me (PRON)\n",
            "Token 16: to (PART)\n",
            "Token 17: create (VERB)\n",
            "Token 18: an (DET)\n",
            "Token 19: account (NOUN)\n",
            "Token 20: or (CCONJ)\n",
            "Token 21: log (VERB)\n",
            "Token 22: using (VERB)\n",
            "Token 23: Google (PROPN)\n",
            "Token 24: or (CCONJ)\n",
            "Token 25: FB (PROPN)\n",
            "Token 26: . (PUNCT)\n",
            "Token 27: I (PRON)\n",
            "Token 28: used (VERB)\n",
            "Token 29: my (PRON)\n",
            "Token 30: Google (PROPN)\n",
            "Token 31: one (NOUN)\n",
            "Token 32: only (ADV)\n",
            "Token 33: to (PART)\n",
            "Token 34: discover (VERB)\n",
            "Token 35: everything (PRON)\n",
            "Token 36: was (AUX)\n",
            "Token 37: gone (VERB)\n",
            "Token 38: ! (PUNCT)\n"
          ]
        }
      ],
      "source": [
        "## Import the libraries\n",
        "import spacy\n",
        "## Load the language model for the language you need\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "## Do tokenization\n",
        "doc = nlp(df.content[1])\n",
        "for i, token in enumerate(doc):\n",
        "    #print(\"Token {}: {}\".format(str(i), token.text))\n",
        "    print(\"Token {}: {} ({})\".format(str(i), token.text, token.pos_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X55d7q-dAleh"
      },
      "source": [
        "All the code does is tokenize the text based on a pre-built language model.\n",
        "\n",
        "Try putting different running text into the `nlp()` part of the code above. The tokenizer is quite robust and it includes a series of built-in rules that deal with exceptions and special cases such as those tokens that contain puctuations like \"`\" and \".\", \"-\", etc. You can even add your own rules, find out how [here](https://spacy.io/usage/linguistic-features#special-cases).\n",
        "\n",
        "Other tools you can use for tokenization are the [Keras Tokenizer API](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer), [Hugging Face Tokenizer](https://github.com/huggingface/tokenizers) and [NLTK](https://www.nltk.org/), which we are going to use for our data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qseAQoTkZBhF"
      },
      "source": [
        "### **3.1.2 NLTK**\n",
        "\n",
        "[NLTK](https://www.nltk.org/) stands for **Natural Language Toolkit**. It is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWr3glXzDE5l",
        "outputId": "32135128-e479-4a4b-ef18-7ee3c20fa04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Let's tokenize the data; we will do so using the nltk library\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXf_NCOsDULD",
        "outputId": "85d595fa-fdaf-4829-d607-adf7a8342276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Update', ':', 'After', 'getting', 'a', 'response', 'from', 'the', 'developer', 'I', 'would', 'change', 'my', 'rating', 'to', '0', 'stars', 'if', 'possible', '.', 'These', 'guys', 'hide', 'behind', 'confusing', 'and', 'opaque', 'terms', 'and', 'refuse', 'to', 'budge', 'at', 'all', '.', 'I', \"'m\", 'so', 'annoyed', 'that', 'my', 'money', 'has', 'been', 'lost', 'to', 'them', '!', 'Really', 'terrible', 'customer', 'experience', '.', 'Original', ':', 'Be', 'very', 'careful', 'when', 'signing', 'up', 'for', 'a', 'free', 'trial', 'of', 'this', 'app', '.', 'If', 'you', 'happen', 'to', 'go', 'over', 'they', 'automatically', 'charge', 'you', 'for', 'a', 'full', 'years', 'subscription', 'and', 'refuse', 'to', 'refund', '.', 'Terrible', 'customer', 'experience', 'and', 'the', 'app', 'is', 'just', 'OK', '.']\n",
            "CPU times: user 8.16 s, sys: 68.5 ms, total: 8.23 s\n",
            "Wall time: 11 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "all_texts = list(df.content)\n",
        "all_texts_tokenized = [nltk.word_tokenize(t) for t in all_texts]\n",
        "print(all_texts_tokenized[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JdUNF24ZjuN"
      },
      "source": [
        "## **3.2 Emoji detection**\n",
        "\n",
        "Emoji lexicons are one of the key components for detecting emotions.\n",
        "Since emoji characters are a subset of a large Unicode character set,\n",
        "we will use the python package [emoji](https://github.com/carpedm20/emoji/) to demojize the emoji lexicons."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J7hMhcycK4N",
        "outputId": "3277530c-9a71-4fa5-f5ef-75ad66aab662"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.5.1.tar.gz (356 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.3/356.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.5.1-py2.py3-none-any.whl size=351210 sha256=e5044c45f5a633b31b54fd379944d43dce382bbe55c75885f2cba8862a2d8fee\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/92/44/e2ef13f803aa08711819357e6de0c5fe67b874671141413565\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G2bgj-ca1NBG"
      },
      "outputs": [],
      "source": [
        "#!pip install emoji\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57_yRv_4bhX4",
        "outputId": "e6422427-9241-46a2-9d2d-3f7c7475192f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supported languages: ['en', 'es', 'ja', 'ko', 'pt', 'it', 'fr', 'de', 'fa', 'id', 'zh']\n",
            "First five emoticons with their english translation: [('🥇', ':1st_place_medal:'), ('🥈', ':2nd_place_medal:'), ('🥉', ':3rd_place_medal:'), ('🆎', ':AB_button_(blood_type):'), ('🏧', ':ATM_sign:')]\n"
          ]
        }
      ],
      "source": [
        "# You can check a list of emoticons by emoji.UNICODE_EMOJI\n",
        "print('Supported languages: {}'.format(list(emoji.LANGUAGES)))\n",
        "print('First five emoticons with their english translation: {}'.format([(emoticon[0], emoticon[1]['en'])\n",
        "                                                                    for emoticon in list(emoji.EMOJI_DATA.items())[0:5]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SlFCQrva-Z2",
        "outputId": "8d3986cd-775c-4e50-85e4-b781a3b7d7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This was originally a 5 star app, but now you can only use it by allowing it access to either your emails or Facebook! 😡😡😡 I am definitely not happy to allow this so have deleted the app. Would give it zero stars if I could.\n"
          ]
        }
      ],
      "source": [
        "# We will first check one of the reviews which contain the emojis\n",
        "print(all_texts[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "iLKPdroBa74B",
        "outputId": "d6d6cac3-db82-4fa2-d64d-e488c6d133e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This was originally a 5 star app, but now you can only use it by allowing it access to either your emails or Facebook! :enraged_face::enraged_face::enraged_face: I am definitely not happy to allow this so have deleted the app. Would give it zero stars if I could.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Then we will use the demojize function to convert unicode set to text\n",
        "emoji.demojize(all_texts[15], language='en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_JRXbV37u5Y",
        "outputId": "b0144b66-71c2-47e8-d0ff-8ac437aca692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'was', 'originally', 'a', '5', 'star', 'app', ',', 'but', 'now', 'you', 'can', 'only', 'use', 'it', 'by', 'allowing', 'it', 'access', 'to', 'either', 'your', 'emails', 'or', 'facebook', '!', ':', 'enraged_face', ':', ':enraged_face', ':', ':enraged_face', ':', 'i', 'am', 'definitely', 'not', 'happy', 'to', 'allow', 'this', 'so', 'have', 'deleted', 'the', 'app', '.', 'would', 'give', 'it', 'zero', 'stars', 'if', 'i', 'could', '.']\n",
            "this was originally a 5 star app , but now you can only use it by allowing it access to either your emails or facebook ! : enraged_face : :enraged_face : :enraged_face : i am definitely not happy to allow this so have deleted the app . would give it zero stars if i could .\n"
          ]
        }
      ],
      "source": [
        "# So to combine 3.1 tokenization and 3.2 Emoji detection together with lower case, we will do the following:\n",
        "all_texts = list(df.content)\n",
        "all_texts_preprocessed_tokenized = [nltk.word_tokenize(emoji.demojize(t.lower(), language='en')) for t in all_texts]\n",
        "print(all_texts_preprocessed_tokenized[15])\n",
        "all_texts_preprocessed = [' '.join(text) for text in all_texts_preprocessed_tokenized]\n",
        "print(all_texts_preprocessed[15])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9uveJKJeLHY"
      },
      "source": [
        "To fit your needs, there are also some common text preprocessing steps:\n",
        "* **lemmatization** (playing -> play)\n",
        "* **stemming** (troubled -> troubl)\n",
        "* **stop words removal** (a, the, is, are, ...)\n",
        "* **punctuation removal**\n",
        "* **abbreviation conversion** (b4 -> before)\n",
        "* **lower case** (The -> the)\n",
        "* **digits conversion** (1549 -> 0000)\n",
        "* **[regular expression](https://regexone.com/)**\n",
        "* **sentence segmentation**\n",
        "\n",
        "and more to explore.\n",
        "\n",
        "**We leave the above as exercises for you to try out.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VdTANxKnsc8",
        "outputId": "a1df929a-2c54-4d99-df2c-203adaf405aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here I impliment two processing techenics to process our data"
      ],
      "metadata": {
        "id": "GJ0WDAvEouuD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rejv-8B3yLb3"
      },
      "outputs": [],
      "source": [
        "### Exercise: try out different preprocessing steps\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# this function precise if word is verbe, noun,..\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].lower()\n",
        "    tag_dict = {\"a\": wordnet.ADJ,\n",
        "                \"n\": wordnet.NOUN,\n",
        "                \"v\": wordnet.VERB,\n",
        "                \"r\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def processing(doc):\n",
        "  # remove ponctuations\n",
        "  doc=doc.translate(str.maketrans('', '', string.punctuation))\n",
        "  #tokenize the doc\n",
        "  tokens = word_tokenize(doc)\n",
        "  # remove stop words\n",
        "  tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "  # lemmatization\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(word,pos=get_wordnet_pos(word)) for word in tokens]\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "# calling the function to process all_texts_preprocessed\n",
        "all_texts_preprocessed = [processing(doc) for doc in all_texts_preprocessed]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_texts_preprocessed[15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1vOl5r_qGjw",
        "outputId": "009c46c4-eda6-4e46-c789-3b8724eddb3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "originally 5 star app use allow access either email facebook enragedface enragedface enragedface definitely happy allow delete app would give zero star could\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DbwemmV_7eE",
        "outputId": "6db47454-3a8f-4065-c358-a46e9bd12fc3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am : be\n",
            "are : be\n",
            "is : be\n",
            "was : be\n",
            "survival : survival\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"am :\", lemmatizer.lemmatize(\"am\", pos=\"v\"))\n",
        "print(\"are :\", lemmatizer.lemmatize(\"are\", pos=\"v\"))\n",
        "print(\"is :\", lemmatizer.lemmatize(\"is\", pos=\"v\"))\n",
        "print(\"was :\", lemmatizer.lemmatize(\"was\", pos=\"v\"))\n",
        "print(\"survival :\", lemmatizer.lemmatize(\"survival\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Liy4gAoEAez0",
        "outputId": "3d156096-8898-4680-83af-43e0680ef4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing : play\n",
            "played : play\n",
            "plays : play\n",
            "survival : surviv\n"
          ]
        }
      ],
      "source": [
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "print(\"playing :\", stemmer.stem(\"playing\"))\n",
        "print(\"played :\", stemmer.stem(\"played\"))\n",
        "print(\"plays :\", stemmer.stem(\"plays\"))\n",
        "print(\"survival :\", stemmer.stem(\"survival\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDYQk4oWDdrn",
        "outputId": "aea323bc-0692-4db8-bd62-e2abc5685e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "Welcome to web mining course\n"
          ]
        }
      ],
      "source": [
        "# Punctuations removal\n",
        "import string\n",
        "print(string.punctuation)\n",
        "doc = \"Welcome to web mining course!!!\"\n",
        "print(doc.translate(str.maketrans('', '', string.punctuation)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPp9vg5CD6En",
        "outputId": "ee234859-3551-4850-bdfe-67b280467a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love coding and programming.\n",
            "I also love sleeping!\n"
          ]
        }
      ],
      "source": [
        "# Sentence segmentation\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I love coding and programming. I also love sleeping!\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K7yZU95lc1X"
      },
      "source": [
        "# **4. Vectorization**\n",
        "\n",
        "Many machine learning models require numeric representations in form of feature vectors as input. Transforming text to vectors is called **vectorization**.\n",
        "\n",
        "When you are working with textual information, it is imperative to clean your data so as to be able to train more accurate machine learning (ML) models.\n",
        "\n",
        "One of the reasons why transformations like lemmatization and stemming are useful is for normalizing the text before you feed the output to an ML algorithm. For instance, if you are building a sentiment analysis model how can you tell the model that \"smiling\" and \"smile\" refer to the same concept? You may require stemming if you are using [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features combined with a machine learning algorithm such as [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). As you may suspect already, this also requires a really good tokenizer to come up with the features, especially when you work on noisy pieces of text that could be generated from users in a social media site.\n",
        "\n",
        "With a wide variety of NLP tasks, one of the first big steps in the NLP pipeline is to create a vocabulary that will eventually be used to determine the inputs for the model representing the features. In modern NLP techniques such as pretrained language models, you need to process a text corpus. This requires a proper and more sophisticated sentence segmentation and tokenization as we discussed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0a7Ipr8Rv-"
      },
      "source": [
        "## **4.1 Tf-Idf Vectorization (sparse)**\n",
        "\n",
        "A simple and powerful technique, which is mostly used for traditional machine learning models is the so-called Tf-Idf vectorization.\n",
        "\n",
        "Tf-idf is a product of two values:\n",
        "* tf: term frequency (often log-transformed)\n",
        "* idf: inverse document frequency\n",
        "\n",
        "\n",
        "\n",
        "Term frequency (tf) measures how frequently the word t\n",
        "appears in the document d\n",
        "\n",
        "$$\\text{tf}_{td}= \\begin{cases} 1 + \\text{log}_{10} \\text{count}(t,d), & \\text{if  count}(t,d)\n",
        "> 0 \\\\ 0, &\\text{otherwise} \\end{cases}$$\n",
        "\n",
        "Inverse document frequency (idf) is inversely proportional\n",
        "to the number of documents in a corpus that contain t\n",
        "(frequently appeared words among documents will have lower idf values)\n",
        "\n",
        "$$\\text{idf}_t= \\text{log}_{10} \\frac{N}{\\text{df}_t}$$\n",
        "\n",
        "So, the tf-idf value for word t in document d is\n",
        "\n",
        "$$\\text{tfidf}_{td} = \\text{tf}_{td}*\\text{idf}_t$$ .\n",
        "\n",
        "So tfidf values will promote document-specific words, and penalize non-specific words (e.g. a, the, ...)\n",
        "\n",
        "[Gensim](https://radimrehurek.com/gensim/index.html) provides an implementation of a tfidf vectorizer.\n",
        "Let's see how we can use this with our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkceNULCbHOG",
        "outputId": "4f41811e-f1ce-4b56-847d-b68cfb9814dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 9457\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Tokenize content by whitespace\n",
        "tokenized_content = [list(simple_preprocess(review)) for review in all_texts_preprocessed]\n",
        "dct = Dictionary(tokenized_content)  # fit dictionary\n",
        "corpus = [dct.doc2bow(line) for line in tokenized_content]\n",
        "tfidf_model = TfidfModel(corpus)\n",
        "\n",
        "print('Number of features: {}'.format(len(dct)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc3IrdTq8as8"
      },
      "source": [
        "Let's inspect what numbers we get ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6IPGC4PbHOH",
        "outputId": "1ae7a3db-b4ba-447c-c2bb-702c7db385c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 0:\n",
            "update get response developer would change rating 0 star possible guy hide behind confuse opaque term refuse budge annoyed money lose really terrible customer experience original careful signing free trial app happen go automatically charge full year subscription refuse refund terrible customer experience app ok\n",
            "\n",
            "refuse:0.33731059762480065\n",
            "terrible:0.29586363333888765\n",
            "customer:0.28408694820934566\n",
            "budge:0.2552932702185129\n",
            "opaque:0.2552932702185129\n",
            "experience:0.2433227017589473\n",
            "careful:0.20430517312382043\n",
            "signing:0.1961186047286254\n",
            "annoyed:0.1857914035243238\n",
            "hide:0.16798569147545442\n",
            "term:0.1575723004057202\n",
            "original:0.15331707602912795\n",
            "refund:0.15215540457939117\n",
            "charge:0.1506767863501512\n",
            "trial:0.14961615431252917\n",
            "behind:0.143127681383801\n",
            "rating:0.13224143233848284\n",
            "possible:0.13077235783325825\n",
            "response:0.1304166407162745\n",
            "happen:0.13006531528089466\n",
            "guy:0.12954632827358065\n",
            "confuse:0.12677181743085553\n",
            "automatically:0.12258578943806324\n",
            "ok:0.1197760921935554\n",
            "money:0.1181225234124619\n",
            "lose:0.11778035096744018\n",
            "developer:0.10840038395641019\n",
            "full:0.10815681329266227\n",
            "subscription:0.10712478670869316\n",
            "year:0.09195599011154082\n",
            "star:0.0859558421440455\n",
            "free:0.08573438578269864\n",
            "change:0.08029592865302523\n",
            "update:0.07816101836541409\n",
            "go:0.07622775778036302\n",
            "really:0.06719185721277432\n",
            "get:0.06063184573255716\n",
            "would:0.05901966466977503\n",
            "app:0.04119682303877346\n"
          ]
        }
      ],
      "source": [
        "doc = 0 #Check for our first review in our dataset\n",
        "print('Text 0:\\n{}\\n'.format(all_texts_preprocessed[0]))\n",
        "\n",
        "# Inspect tf-idf scores of document sorted by the similarity score\n",
        "for w,s in sorted(tfidf_model[corpus[doc]], reverse=True, key=lambda x: x[1]):\n",
        "    print('{}:{}'.format(dct[w], s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klLuSON2pUJy"
      },
      "source": [
        "**You can see that there are actually some missing tokens after applying the tfidf-vectorizer (e.g. tokens with the length less than 2). Why is this the case? How can you modify it?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZIoifyLx6kN",
        "outputId": "423e9149-02a9-4616-94a9-59ca6a2c56fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 9535\n"
          ]
        }
      ],
      "source": [
        "# Tokenize content by whitespace and decrease min length to 1\n",
        "tokenized_content = [list(simple_preprocess(review, min_len=1)) for review in all_texts_preprocessed]\n",
        "dct = Dictionary(tokenized_content)  # fit dictionary\n",
        "corpus = [dct.doc2bow(line) for line in tokenized_content]\n",
        "tfidf_model = TfidfModel(corpus)\n",
        "\n",
        "print('Number of features: {}'.format(len(dct)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Si07iQHe0j",
        "outputId": "da1e7ef1-7aa9-4580-b17f-e2c337c6bd49",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 0:\n",
            "update get response developer would change rating 0 star possible guy hide behind confuse opaque term refuse budge annoyed money lose really terrible customer experience original careful signing free trial app happen go automatically charge full year subscription refuse refund terrible customer experience app ok\n",
            "\n",
            "refuse:0.33731059762480065\n",
            "terrible:0.29586363333888765\n",
            "customer:0.28408694820934566\n",
            "budge:0.2552932702185129\n",
            "opaque:0.2552932702185129\n",
            "experience:0.2433227017589473\n",
            "careful:0.20430517312382043\n",
            "signing:0.1961186047286254\n",
            "annoyed:0.1857914035243238\n",
            "hide:0.16798569147545442\n",
            "term:0.1575723004057202\n",
            "original:0.15331707602912795\n",
            "refund:0.15215540457939117\n",
            "charge:0.1506767863501512\n",
            "trial:0.14961615431252917\n",
            "behind:0.143127681383801\n",
            "rating:0.13224143233848284\n",
            "possible:0.13077235783325825\n",
            "response:0.1304166407162745\n",
            "happen:0.13006531528089466\n",
            "guy:0.12954632827358065\n",
            "confuse:0.12677181743085553\n",
            "automatically:0.12258578943806324\n",
            "ok:0.1197760921935554\n",
            "money:0.1181225234124619\n",
            "lose:0.11778035096744018\n",
            "developer:0.10840038395641019\n",
            "full:0.10815681329266227\n",
            "subscription:0.10712478670869316\n",
            "year:0.09195599011154082\n",
            "star:0.0859558421440455\n",
            "free:0.08573438578269864\n",
            "change:0.08029592865302523\n",
            "update:0.07816101836541409\n",
            "go:0.07622775778036302\n",
            "really:0.06719185721277432\n",
            "get:0.06063184573255716\n",
            "would:0.05901966466977503\n",
            "app:0.04119682303877346\n"
          ]
        }
      ],
      "source": [
        "doc = 0 #Check for our first review in our dataset\n",
        "print('Text 0:\\n{}\\n'.format(all_texts_preprocessed[0]))\n",
        "\n",
        "# Inspect tf-idf scores of document sorted by the similarity score\n",
        "for w,s in sorted(tfidf_model[corpus[doc]], reverse=True, key=lambda x: x[1]):\n",
        "    print('{}:{}'.format(dct[w], s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QPkRuV6RbHOI"
      },
      "outputs": [],
      "source": [
        "from gensim import matutils\n",
        "# vectorize all documents with tf-idf\n",
        "tfidf_vectorization_csr = matutils.corpus2csc(tfidf_model[corpus], num_terms=len(dct))\n",
        "X_tfidf_vectorization = tfidf_vectorization_csr.T.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zimx86-x80yD"
      },
      "source": [
        "## **4.2 Word Embedding Vectorization (dense)**\n",
        "\n",
        "**Intro**\n",
        "\n",
        "Using TfIdf value for each token as the text representation will lead to the following problems:\n",
        "* high dimensional feature vector due to large size of vocabulary (V) or unseen words\n",
        "* lead to highly sparse vector (i.e. a lot of zeros)\n",
        "\n",
        "Here comes the question: how can we represent a word by encoding the co-occurrence information within context, but having a more dense representation (d << V)?\n",
        "\n",
        "**Distributional Hypothesis**\n",
        "* Words which are similar in meaning occur in similar contexts\n",
        "* Words that occur in the same contexts tend to have similar meanings\n",
        "\n",
        "Learn dense word representations (e.g. d=50, 100, 300, ...) by expoiting co-occurrence statistics with neighboring words. Each word is represented by a dense vector and the dimension of the semantic representation d is usually much\n",
        "smaller than the size of the vocabulary (d << V). All dimensions contain real-valued numbers (possibly normalized between −1 and 1).\n",
        "\n",
        "* **CBOW**: predict center word from neighboring words\n",
        "* **Skip-gram**: predict neighboring words from center word\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*cuOmGT7NevP9oJFJfVpRKA.png\" width=800></img>\n",
        "</p>\n",
        "\n",
        "* **Glove**: leveraging global word to word co-occurance counts on the entire corpus\n",
        "* **FastText**: represent words by neighboring ngrams, capturing out-of-vocabulary (OOV) words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e6y7cWw_TX2"
      },
      "source": [
        "In order to use pretrained word embeddings, you just have to download the vectors from the authors web site. Often, it is just a text file with the following structure:\n",
        "\\<word> \\<tab> \\<vector> .\n",
        "\n",
        "Here, we can again make use of gensim, which already provides some [pretrained models](https://github.com/RaRe-Technologies/gensim-data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fe4u6oNXBoEj"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YzaemW_BFlZ",
        "outputId": "f680a7de-d66a-4aa2-f0ea-42cbbb202574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================================--] 97.6% 64.4/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the glove model\n",
        "glove_model = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjXfLN7KUvE",
        "outputId": "9680f082-79be-4aa2-ebbf-9a8073f76732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 400000\n"
          ]
        }
      ],
      "source": [
        "print('Vocab size: {}'.format(len(glove_model.index_to_key)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnC0r1qSCAD_",
        "outputId": "a020a04a-6cb5-42fc-9439-59cb646b1689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.3121e-02,  7.1226e-01, -2.2566e-01,  1.2239e-01,  7.2298e-01,\n",
              "        5.5787e-01, -6.4484e-03, -7.0540e-01, -3.2206e-01,  1.2796e-01,\n",
              "       -7.7531e-02,  5.5125e-02,  3.8379e-02,  9.5295e-01,  4.3992e-02,\n",
              "        4.5025e-01, -1.1435e-01, -1.2781e-03, -3.2919e-01, -1.8721e+00,\n",
              "        1.0702e+00, -1.1634e-01, -6.2644e-01, -6.1095e-01, -4.1408e-01,\n",
              "       -5.5053e-01, -7.0974e-01,  1.4821e+00,  5.3134e-01, -5.3206e-01,\n",
              "        2.1137e+00, -1.0961e+00,  4.8239e-01, -1.6375e-01, -6.2490e-01,\n",
              "        7.2829e-01,  5.1436e-01,  8.4971e-01,  1.0365e+00,  7.4664e-02,\n",
              "        1.0125e+00,  4.7441e-01,  4.2126e-01, -4.9965e-02,  5.3149e-01,\n",
              "        1.2321e+00, -2.7239e-01, -1.4639e+00, -3.3859e-01, -9.7446e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "glove_model[\"glass\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJlha75XB-Ls",
        "outputId": "5bf4a374-67fa-4686-df2d-c3a0a35fe3c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('plastic', 0.79425048828125),\n",
              " ('metal', 0.7708716988563538),\n",
              " ('walls', 0.7700635194778442),\n",
              " ('marble', 0.7638523578643799),\n",
              " ('wood', 0.7624280452728271),\n",
              " ('ceramic', 0.7602593302726746),\n",
              " ('pieces', 0.7589112520217896),\n",
              " ('stained', 0.7528817653656006),\n",
              " ('tile', 0.748193621635437),\n",
              " ('furniture', 0.7463858723640442)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "glove_model.most_similar(\"glass\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spAPjv2F_Hax"
      },
      "source": [
        "We can transform, i.e., vectorize, our text by looking up the pretrained embedding for each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk5fRWnqCs_Y",
        "outputId": "f1e71e6f-43db-4565-b2ad-358c5df3cd29",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.25676 ,  0.8549  ,  1.1003  ,  0.95363 ,  0.36585 , -1.3029  ,\n",
              "         1.0754  , -0.18461 , -0.67674 ,  0.37637 , -0.029637,  0.51698 ,\n",
              "        -0.19248 , -0.41863 , -0.71144 ,  0.12564 , -0.42965 ,  0.61456 ,\n",
              "         0.41819 ,  0.27606 , -0.48635 , -0.32585 ,  0.67748 ,  0.15916 ,\n",
              "         0.35051 , -0.29393 , -0.80439 , -0.15939 ,  0.012475, -0.58404 ,\n",
              "         2.1353  , -0.1547  , -0.5739  ,  1.4522  ,  0.6124  , -0.68752 ,\n",
              "         1.2839  , -0.54631 , -0.35737 ,  0.57323 ,  0.3546  , -0.37465 ,\n",
              "        -0.74628 , -0.074561, -0.48471 ,  0.067343, -0.039338, -0.22177 ,\n",
              "         0.099708,  0.55553 ], dtype=float32),\n",
              " array([-3.5559e-01,  1.2386e+00,  1.4348e+00,  1.0447e+00,  1.0335e+00,\n",
              "         1.0445e-01,  2.7760e-01, -1.2675e+00, -9.5788e-01, -5.9603e-01,\n",
              "        -1.8280e-01, -1.8247e-02, -9.3553e-01, -4.9706e-01,  8.5845e-03,\n",
              "         8.6971e-01, -3.5250e-01, -1.7587e-01, -6.7203e-01, -4.9188e-01,\n",
              "         4.9252e-05,  1.9287e-01,  1.2353e+00,  7.1928e-01, -3.7632e-01,\n",
              "         6.0005e-01, -2.1616e-01,  2.6368e-01,  3.7403e-01,  8.5283e-01,\n",
              "         2.2797e+00, -2.9896e-01,  1.1625e-01,  7.9111e-01,  5.7041e-01,\n",
              "        -1.6061e+00, -2.0628e-02, -1.1018e+00,  1.2016e+00,  2.8124e-01,\n",
              "         4.4690e-01, -5.8974e-01, -3.1770e-01,  4.9358e-01, -3.8290e-01,\n",
              "         3.3543e-01,  7.0644e-01,  1.6022e-01,  1.1328e+00,  6.9397e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.07487 ,  0.7268  ,  0.60202 ,  0.67041 , -0.4931  ,  0.93332 ,\n",
              "         0.56347 , -0.6014  , -0.24315 , -0.65394 , -1.0592  , -0.022451,\n",
              "        -0.18103 , -0.60974 , -0.92036 , -0.61579 ,  0.18427 , -0.20126 ,\n",
              "        -0.17767 , -0.73492 , -1.0046  , -0.93514 ,  0.81081 ,  0.26421 ,\n",
              "        -0.81027 , -1.1659  ,  0.22443 , -0.11386 , -0.65991 , -0.22088 ,\n",
              "         1.9264  , -0.18013 , -0.67806 ,  0.097938,  0.7236  , -1.463   ,\n",
              "         0.672   ,  0.19596 ,  0.64471 , -0.1105  ,  0.61934 ,  0.87038 ,\n",
              "        -0.36938 , -0.49484 , -0.054509,  1.2095  ,  0.14817 , -0.3651  ,\n",
              "        -0.34448 ,  2.5774  ], dtype=float32),\n",
              " array([ 0.21705 ,  0.46515 , -0.46757 ,  0.10082 ,  1.0135  ,  0.74845 ,\n",
              "        -0.53104 , -0.26256 ,  0.16812 ,  0.13182 , -0.24909 , -0.44185 ,\n",
              "        -0.21739 ,  0.51004 ,  0.13448 , -0.43141 , -0.03123 ,  0.20674 ,\n",
              "        -0.78138 , -0.20148 , -0.097401,  0.16088 , -0.61836 , -0.18504 ,\n",
              "        -0.12461 , -2.2526  , -0.22321 ,  0.5043  ,  0.32257 ,  0.15313 ,\n",
              "         3.9636  , -0.71365 , -0.67012 ,  0.28388 ,  0.21738 ,  0.14433 ,\n",
              "         0.25926 ,  0.23434 ,  0.4274  , -0.44451 ,  0.13813 ,  0.36973 ,\n",
              "        -0.64289 ,  0.024142, -0.039315, -0.26037 ,  0.12017 , -0.043782,\n",
              "         0.41013 ,  0.1796  ], dtype=float32),\n",
              " array([-0.37915 ,  0.61848 ,  0.9593  ,  0.90403 ,  0.36806 ,  0.022972,\n",
              "         0.16795 , -1.5309  , -0.060533, -0.25    ,  0.15031 ,  0.31967 ,\n",
              "        -0.68914 , -0.78626 , -0.015825,  0.50531 , -0.8473  , -0.12353 ,\n",
              "         0.078526, -0.96024 , -0.54313 , -0.33516 ,  0.38932 ,  0.19461 ,\n",
              "        -1.1688  , -0.86608 , -0.39178 ,  0.24183 ,  0.32862 , -0.78755 ,\n",
              "         2.4884  ,  0.71015 , -0.53114 ,  0.89593 , -0.23053 , -0.82023 ,\n",
              "         0.34425 , -0.96866 , -0.15143 , -0.44912 ,  0.89513 , -0.01659 ,\n",
              "        -0.2749  ,  0.27948 ,  0.77936 , -0.31944 ,  0.16756 , -0.62515 ,\n",
              "         0.053323,  0.62023 ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "all_texts_tokenized_embedded = [[glove_model[w] for w in t if w in glove_model]  for t in all_texts_preprocessed]\n",
        "all_texts_tokenized_embedded[0][0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXwaXveDNXv"
      },
      "source": [
        "Now, we have assigned a vector to each word. But how to get a sentence representation? For instance, we can just average the individual word vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM9FmubeDdpR",
        "outputId": "179d824d-553d-48cf-9f40-631dd5363551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "all_texts_tokenized_embedded = [[glove_model[w].astype(float) for w in t if w in glove_model] for t in all_texts_preprocessed]\n",
        "X_all_texts_tokenized_embedded_averaged = [np.average(t, axis=0) for t in all_texts_tokenized_embedded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-b3qjtr8KQQ",
        "outputId": "808e5d8e-1cc2-4fee-efd3-a5765c6121a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "یاشار\n",
            "شكرا\n",
            "சிறந்த செயலி மாற்றத்தை காண வழி\n",
            "♡♡\n",
            "عملي جدآ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "提醒方式可設定成全螢幕鬧鐘模式，不會錯過\n",
            "\n",
            "ট্যাবে হরাইজন্টাল ফোনে ভার্টিকাল। ফলে ট্যাবে লিখতে অসুবিধা হচ্ছে। এবং লগ ইন করতে হয় যেকোন অ্যাকাউন্টে।\n",
            "ট্যাবে হরাইজন্টাল ফোনে ভার্টিকাল। ফলে ট্যাবে লিখতে অসুবিধা হচ্ছে। এবং লগ ইন করতে হয় যেকোন অ্যাকাউন্টে।\n"
          ]
        }
      ],
      "source": [
        "# Further find out that there are some texts which are not representative by using glove\n",
        "for i, k in enumerate(X_all_texts_tokenized_embedded_averaged):\n",
        "    if np.isnan(k).any():\n",
        "        print(all_texts_preprocessed[i])\n",
        "\n",
        "# For these cases we can simply assign a random word vector from gensim.model\n",
        "for i, k in enumerate(X_all_texts_tokenized_embedded_averaged):\n",
        "    if np.isnan(k).any():\n",
        "        X_all_texts_tokenized_embedded_averaged[i]=glove_model[random.choice(glove_model.index_to_key)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMWBV6nvBHrM",
        "outputId": "e2f1cc41-80af-4423-bde5-72a3ccbfadf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "X_all_texts_tokenized_embedded_averaged = np.array(X_all_texts_tokenized_embedded_averaged)\n",
        "X_all_texts_tokenized_embedded_averaged.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoIHJavMrKWR"
      },
      "source": [
        "# **5. ML Framework: scikit-learn (sklearn)**\n",
        "\n",
        "[Scikit-learn](https://scikit-learn.org/stable/) (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means...etc, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR6nzxqbrvnm"
      },
      "source": [
        "## **5.1 Classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44WsA9M0yk_Q",
        "outputId": "0d178994-f403-407c-e877-326b05e97720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15746, 9535)\n",
            "(15746,)\n"
          ]
        }
      ],
      "source": [
        "# Now our input can either be X_tfidf_vectorization or X_all_texts_tokenized_embedded_averaged\n",
        "# Case1: X = X_tfidf_vectorization\n",
        "\n",
        "X = X_tfidf_vectorization\n",
        "print(X.shape)\n",
        "Y = np.array(list(df['sentiment']))\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFYh3Et6zaTh",
        "outputId": "2296bfbd-2ed5-4500-d111-51531dba37b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12596 1575 1575\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split train, val, test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED, shuffle=True)\n",
        "print(len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnXyJuaV1Ual",
        "outputId": "6dc8ea91-1493-4553-a570-c046a2f6871d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: SGD trained for 200 iters\n",
            "Accuracy: 69.33333333333334\n",
            "P: 68.69504463014134, R:69.13717905072424, F1: 68.37413850090623\n",
            "\n",
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced\n",
            "Accuracy: 70.15873015873015\n",
            "P: 69.58697375947699, R:70.01823968277007, F1: 69.4030791615235\n",
            "\n",
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log_loss\n",
            "Accuracy: 68.88888888888889\n",
            "P: 68.30345898396587, R:68.68996833368882, F1: 68.21023715091513\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SGDClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize list of classifiers\n",
        "classifiers_to_test = [\n",
        "    ('SGD trained for 200 iters',\n",
        "         SGDClassifier(max_iter = 200, random_state=RANDOM_SEED)),\n",
        "    ('SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced',\n",
        "         SGDClassifier(max_iter = 200, learning_rate = 'adaptive', eta0=0.1, class_weight='balanced', random_state=RANDOM_SEED)),\n",
        "    ('SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log_loss',\n",
        "        SGDClassifier(max_iter = 200, learning_rate = 'adaptive', eta0=0.1, class_weight='balanced', loss='log_loss', random_state=RANDOM_SEED))\n",
        "]\n",
        "\n",
        "# train evaluate classifiers\n",
        "for name, classifier in classifiers_to_test:\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict Class\n",
        "    y_pred = classifier.predict(X_val)\n",
        "\n",
        "    # Accuracy\n",
        "    print('Classifier: {}'.format(name))\n",
        "    print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)*100))\n",
        "    P, R, F1, _ = precision_recall_fscore_support(y_val, y_pred, average='macro')\n",
        "    print('P: {}, R:{}, F1: {}'.format(P*100, R*100, F1*100))\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmlZhAJLbHOP",
        "outputId": "7bc92247-1ea2-4dd0-cdd0-977e2c3c0510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log_loss\n",
            "Accuracy: 0.7047619047619048\n",
            "P: 0.6945034448411126, R:0.694690736284425, F1: 0.6933800112338578\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best classifier on test set\n",
        "y_pred = classifiers_to_test[1][1].predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print('Classifier: {}'.format(name))\n",
        "print('Accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
        "P, R, F1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "print('P: {}, R:{}, F1: {}'.format(P, R, F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "HbCjJElwbHOP"
      },
      "outputs": [],
      "source": [
        "# Case2: X = X_all_texts_tokenized_embedded_averaged\n",
        "# If our input is the average embedding for the text tokens\n",
        "\n",
        "X = X_all_texts_tokenized_embedded_averaged\n",
        "Y = np.array(list(df['sentiment']))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx9cR-VB1pPq",
        "outputId": "899ea432-da45-4519-9347-c9d647f37f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: SGD trained for 200 iters\n",
            "Accuracy: 0.4165079365079365\n",
            "P: 0.45089300285323325, R:0.4327734486917085, F1: 0.3991312836904224\n",
            "\n",
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced\n",
            "Accuracy: 0.46285714285714286\n",
            "P: 0.46561672411083205, R:0.45363444633376426, F1: 0.4116944894350388\n",
            "\n",
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log\n",
            "Accuracy: 0.47555555555555556\n",
            "P: 0.471177529917509, R:0.4723346903811499, F1: 0.4604813420233828\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize list of classifiers\n",
        "classifiers_to_test = [\n",
        "    ('SGD trained for 200 iters',\n",
        "         SGDClassifier(max_iter = 200, random_state=RANDOM_SEED)),\n",
        "    ('SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced',\n",
        "         SGDClassifier(max_iter = 200, learning_rate = 'adaptive', eta0=0.1, class_weight='balanced', random_state=RANDOM_SEED)),\n",
        "    ('SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log',\n",
        "        SGDClassifier(max_iter = 200, learning_rate = 'adaptive', eta0=0.1, class_weight='balanced', loss='log_loss', random_state=RANDOM_SEED))\n",
        "]\n",
        "\n",
        "# train evaluate classifiers\n",
        "for name, classifier in classifiers_to_test:\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict Class\n",
        "    y_pred = classifier.predict(X_val)\n",
        "\n",
        "    # Accuracy\n",
        "    print('Classifier: {}'.format(name))\n",
        "    print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
        "    P, R, F1, _ = precision_recall_fscore_support(y_val, y_pred, average='macro')\n",
        "    print('P: {}, R:{}, F1: {}'.format(P, R, F1))\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGILL2VMbHOP",
        "outputId": "53460c70-914d-48c6-e656-f08953441469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log\n",
            "Accuracy: 0.4546031746031746\n",
            "P: 0.4322601776693289, R:0.4396400144103374, F1: 0.4298688034809439\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best classifier on test set\n",
        "y_pred = classifiers_to_test[2][1].predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print('Classifier: {}'.format(name))\n",
        "print('Accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
        "P, R, F1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "print('P: {}, R:{}, F1: {}'.format(P, R, F1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyh3Tt6vbHOQ"
      },
      "source": [
        "Use Cross-Validation for hyperparameter tuning.\n",
        "\n",
        "**Running the following cell is computationally expensive and will take some time!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "XQAz8bnEbHOQ",
        "outputId": "b23a31f4-c66a-421f-a35b-22bd550c4295"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_eta0  \\\n",
              "0      60.261515      0.937816         0.077591        0.003278        0.1   \n",
              "1      89.715305      2.436485         0.081461        0.006549      0.001   \n",
              "2      22.041034      0.713180         0.071041        0.003790     0.0001   \n",
              "\n",
              "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
              "0     {'eta0': 0.1}           0.690873           0.673680           0.687177   \n",
              "1   {'eta0': 0.001}           0.594841           0.588329           0.601032   \n",
              "2  {'eta0': 0.0001}           0.615079           0.605002           0.602620   \n",
              "\n",
              "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
              "0           0.670107           0.696705         0.683709        0.010177   \n",
              "1           0.583962           0.592696         0.592172        0.005798   \n",
              "2           0.602223           0.614133         0.607811        0.005637   \n",
              "\n",
              "   rank_test_score  \n",
              "0                1  \n",
              "1                3  \n",
              "2                2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-953ce550-dad7-4476-aabc-6e7f618bf0d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_eta0</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60.261515</td>\n",
              "      <td>0.937816</td>\n",
              "      <td>0.077591</td>\n",
              "      <td>0.003278</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'eta0': 0.1}</td>\n",
              "      <td>0.690873</td>\n",
              "      <td>0.673680</td>\n",
              "      <td>0.687177</td>\n",
              "      <td>0.670107</td>\n",
              "      <td>0.696705</td>\n",
              "      <td>0.683709</td>\n",
              "      <td>0.010177</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>89.715305</td>\n",
              "      <td>2.436485</td>\n",
              "      <td>0.081461</td>\n",
              "      <td>0.006549</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{'eta0': 0.001}</td>\n",
              "      <td>0.594841</td>\n",
              "      <td>0.588329</td>\n",
              "      <td>0.601032</td>\n",
              "      <td>0.583962</td>\n",
              "      <td>0.592696</td>\n",
              "      <td>0.592172</td>\n",
              "      <td>0.005798</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.041034</td>\n",
              "      <td>0.713180</td>\n",
              "      <td>0.071041</td>\n",
              "      <td>0.003790</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>{'eta0': 0.0001}</td>\n",
              "      <td>0.615079</td>\n",
              "      <td>0.605002</td>\n",
              "      <td>0.602620</td>\n",
              "      <td>0.602223</td>\n",
              "      <td>0.614133</td>\n",
              "      <td>0.607811</td>\n",
              "      <td>0.005637</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-953ce550-dad7-4476-aabc-6e7f618bf0d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-953ce550-dad7-4476-aabc-6e7f618bf0d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-953ce550-dad7-4476-aabc-6e7f618bf0d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score is 0.6837085452150954 with params {'eta0': 0.1}\n",
            "Classifier: SGD trained for 200 iters, lr=adaptive, eta0=0.1, class_weights=balanced, loss=log\n",
            "Accuracy: 0.7031746031746032\n",
            "P: 0.6951444797876968, R:0.6970183025190976, F1: 0.6937560910613675\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use Cross Validation to tune hyperparameters\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X = X_tfidf_vectorization\n",
        "Y = np.array(list(df['sentiment']))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
        "\n",
        "# create an classifier\n",
        "classifier = SGDClassifier(max_iter=200, learning_rate = 'adaptive', class_weight='balanced', random_state=RANDOM_SEED)\n",
        "\n",
        "# specify the parameter grid\n",
        "parameters = {\n",
        "    'eta0': [0.1, 0.001, 0.0001]\n",
        "}\n",
        "\n",
        "# specify the cross validation\n",
        "stratified_5_fold_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# create the grid search instance\n",
        "grid_search_estimator = GridSearchCV(classifier, parameters, scoring='accuracy', cv=stratified_5_fold_cv, return_train_score=False)\n",
        "\n",
        "# run the grid search\n",
        "grid_search_estimator.fit(X_train,y_train)\n",
        "\n",
        "# print the results of all hyper-parameter combinations\n",
        "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
        "display(results)\n",
        "\n",
        "# print the best parameter setting\n",
        "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
        "\n",
        "# Predict Class\n",
        "y_pred = grid_search_estimator.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print('Classifier: {}'.format(name))\n",
        "print('Accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
        "P, R, F1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "print('P: {}, R:{}, F1: {}'.format(P, R, F1))\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTFRXMLTKm0p",
        "outputId": "626f9018-f457-4595-90a8-906d31c7c57d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.06684374 0.         ... 0.         0.         0.        ]]\n",
            "Predicted Class: positive\n"
          ]
        }
      ],
      "source": [
        "### How about writing a prediction function for inputing an unseen text, and check the predicted result.\n",
        "x_new = \"I like this app. It's super useful!😄\"\n",
        "x_new_preprocessed = ' '.join(nltk.word_tokenize(emoji.demojize(x_new.lower(), language='en')))\n",
        "\n",
        "# Vectorize with gensim\n",
        "x_new_preprocessed_corpus = dct.doc2bow(simple_preprocess(x_new_preprocessed))\n",
        "x_new_preprocessed_tfidf = tfidf_model[x_new_preprocessed_corpus]\n",
        "\n",
        "# Convert vectorization to process in sklearn\n",
        "x_new_preprocessed_tfidf_csr = matutils.corpus2csc([x_new_preprocessed_tfidf], num_terms=len(dct))\n",
        "x_new_preprocessed_tfidf_vectorization = x_new_preprocessed_tfidf_csr.T.toarray()\n",
        "print(x_new_preprocessed_tfidf_vectorization)\n",
        "\n",
        "mapping_class = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "print('Predicted Class: {}'.format(mapping_class[grid_search_estimator.predict(x_new_preprocessed_tfidf_vectorization)[0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw3MbJ5uJrHY"
      },
      "source": [
        "### More advanced: try fasttext embedding instead of glove to deal with OOV words\n",
        "https://github.com/facebookresearch/fastText/\n",
        "1. !pip install fasttext\n",
        "2. Download the model from their website\n",
        "\n",
        "> model = fasttext.load_model(\"model_filename.bin\")\n",
        "\n",
        "> model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
        "\n",
        "3. try other classifiers from scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyQeSPyxbHOR",
        "outputId": "767fb38b-33f1-40cd-e2fb-23b9273d8212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.10.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we applied fasttext.train_supervised on prepocessed data\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_texts_preprocessed, Y, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)"
      ],
      "metadata": {
        "id": "aDgJI1TxYc9i"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test\n",
        "\n",
        "\n",
        "# Write the train data to file\n",
        "with open(\"train_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for i in range(len(X_train)):\n",
        "        f.write(\"__label__\" + str(y_train[i]) + \" \" + X_train[i] +\"\\n\")\n",
        "\n",
        "\n",
        "with open(\"test_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for i in range(len(X_test)):\n",
        "        f.write(\"__label__\" + str(y_test[i]) + \" \" + X_test[i] +\"\\n\")"
      ],
      "metadata": {
        "id": "Kb__kYGrTBiE"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "model = fasttext.train_supervised(input=\"train_data.txt\", epoch=50)\n",
        "# Save the model\n",
        "model.save_model('text_classification_model.bin')"
      ],
      "metadata": {
        "id": "LoLSBaajav2Q"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "result = model.test(\"test_data.txt\")\n",
        "print(\"Test Accuracy:\", result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znIsN8JOKsT8",
        "outputId": "aed6eed4-82f7-4f78-9513-ab64ad82b573"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7292063492063492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "text = \"I love working on NlP project.\"\n",
        "mapping_class = {\"__label__0\": \"negative\", \"__label__1\": \"neutral\", \"__label__2\": \"positive\"}\n",
        "\n",
        "labels, prob = model.predict(text)\n",
        "print(\"Label:\", mapping_class[labels[0]])\n",
        "print(\"Probability:\", prob[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAJgeeEcc3y0",
        "outputId": "25bcd442-b8fe-41a5-f29a-b76aca7bac78"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: positive\n",
            "Probability: 0.9963294267654419\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}